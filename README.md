# Proyecto Web Scraper Avanzado

Plataforma completa de **scraping dinÃ¡mico y estÃ¡tico**, procesamiento de datos, almacenamiento en PostgreSQL, API en JSON y dashboard interactivo.  
Totalmente contenedorizado con **Docker + Docker Compose**.

---

## ğŸ“Œ DescripciÃ³n General

Este sistema realiza scraping de:

- **Sitios dinÃ¡micos** (MercadoLibre) con **Playwright**
- **Sitios estÃ¡ticos** usando **Requests + BeautifulSoup**
- Descarga archivos y detecta cambios mediante **hash SHA-256**
- Guarda toda la informaciÃ³n en **PostgreSQL**
- Expone JSON a travÃ©s de una **API Flask**
- Visualiza datos en un **dashboard web**
- Automatiza scraping cada 30 minutos con **APScheduler**

El proyecto estÃ¡ diseÃ±ado siguiendo las exigencias del curso UTN **TecnologÃ­as Web III**.

---

## ğŸ›  TecnologÃ­as Utilizadas

### ğŸ” Scraping
- **Playwright (Chromium headless)** â€” Scraping dinÃ¡mico real  
- **BeautifulSoup + Requests** â€” Scraping estÃ¡tico  
- **Hashing SHA-256** â€” DetecciÃ³n de cambios  

### ğŸ—„ Base de Datos
- **PostgreSQL 16**  
- **SQL Schema + backups automÃ¡ticos**

### ğŸŒ API
- **Flask**, **Flask-CORS**  
- Endpoints REST estructurados  

### ğŸ’» Frontend
- HTML5, CSS3, JavaScript  
- Bootstrap 5  
- FullCalendar.js  

### âš™ AutomatizaciÃ³n
- **APScheduler**  
- Scheduler cada 30 min  
- Logging estructurado  

### ğŸ³ Contenedores
- Docker  
- Docker Compose  
- Imagen con Playwright + Chromium preinstalado  

---

## ğŸ“‚ Estructura del Proyecto

```
proyecto-scraper/
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ scraper_dynamic.py
â”‚   â””â”€â”€ scraper_static.py
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ db_manager.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ api/
â”‚   â””â”€â”€ json_api_server.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ styles.css
â”‚       â”œâ”€â”€ main.js
â”‚       â”œâ”€â”€ results.js
â”‚       â”œâ”€â”€ files.js
â”‚       â””â”€â”€ calendar.js
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ helpers.py
â”‚   â””â”€â”€ json_generator.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ results.json
â”‚   â”œâ”€â”€ files.json
â”‚   â””â”€â”€ events.json
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ scraper.log
â”‚
â”œâ”€â”€ downloads/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ guia_inicio.md
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ main.py
â”œâ”€â”€ scheduler.py
â”œâ”€â”€ setup_database.py
â”œâ”€â”€ database_schema.sql
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## âš™ ConfiguraciÃ³n (Modo Docker)

### 1ï¸âƒ£ Crear archivo `.env`

```
DB_HOST=db
DB_PORT=5432
DB_NAME=scraper_db
DB_USER=postgres
DB_PASSWORD=postgres

API_HOST=0.0.0.0
API_PORT=5000

SCRAPE_INTERVAL=30
MAX_PAGES=3
SEARCH_TERM=laptop

STATIC_URL=https://file-examples.com/index.php/sample-documents-download/
```

---

### 2ï¸âƒ£ Ejecutar Docker Compose

```
docker-compose build
docker-compose up
```

Servicios desplegados:

| Servicio | DescripciÃ³n |
|---------|-------------|
| scraper_dynamic | Scraping de MercadoLibre |
| scraper_static | Descarga de archivos estÃ¡ticos |
| scraper_scheduler | Tareas automÃ¡ticas cada 30 minutos |
| scraper_api | API Flask |
| scraper_db | PostgreSQL |

---

### 3ï¸âƒ£ Acceder a los servicios

| Servicio | URL |
|----------|-----|
| API | http://localhost:5000 |
| Dashboard | frontend/index.html |
| PostgreSQL | localhost:5432 |

---

## â–¶ Uso del Proyecto

### EjecuciÃ³n manual

```
python main.py
```

### Scheduler

```
python scheduler.py
```

### API

```
python api/json_api_server.py
```

---

## ğŸ“¡ Endpoints de la API

| MÃ©todo | Endpoint | DescripciÃ³n |
|--------|----------|-------------|
| GET | `/` | Estado de la API |
| GET | `/api/products` | Lista de productos |
| GET | `/api/products/<id>` | Producto individual |
| GET | `/api/files` | Archivos descargados |
| GET | `/api/events` | Eventos del sistema |
| GET | `/api/stats` | EstadÃ­sticas |
| GET | `/api/categories` | CategorÃ­as detectadas |

---

## â­ Funcionalidades Principales

- Scraping dinÃ¡mico con Playwright (Chromium)
- Scraping estÃ¡tico + descarga de archivos
- ComparaciÃ³n con hashing SHA-256
- Base de datos PostgreSQL integrada
- API REST profesional
- Dashboard moderno y modular
- Calendario de eventos con FullCalendar
- AutomatizaciÃ³n completa Dockerizada
- Logs detallados y gestiÃ³n robusta de errores

---

## ğŸ§ª Testing

```
python test_api.py
```

---

## ğŸ“ DetecciÃ³n de Cambios

El sistema detecta:

- Nuevos registros â†’ Insertar  
- Registros modificados â†’ Actualizar  
- Archivos modificados â†’ Reemplazar  
- Archivos eliminados â†’ Borrarlos localmente  

---

## ğŸ¨ DiseÃ±o ArquitectÃ³nico

```
Scraper dinÃ¡mico / estÃ¡tico
        â†“
Base de Datos PostgreSQL
        â†“
JSON Generator
        â†“
API Flask
        â†“
Dashboard Web
```

---

## ğŸ‘¥ Autores

- **Cristian Rojas**  
- **SebastiÃ¡n AlpÃ­zar**  
- **RaÃºl Quesada**  

---

## ğŸ“ Proyecto AcadÃ©mico UTN

Universidad TÃ©cnica Nacional (UTN)  
IngenierÃ­a en TecnologÃ­as de la InformaciÃ³n  
Curso: **TecnologÃ­as y Sistemas Web III**  
Profesor: **AndrÃ©s Joseph JimÃ©nez Leandro**  
Ciclo III-C, 2025  

---

## ğŸ“„ Licencia

Proyecto de uso acadÃ©mico â€” No comercial.
